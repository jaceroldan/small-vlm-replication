{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./torch-2.5.0a0+872d972e41.nv24.08.17622132-cp310-cp310-linux_aarch64.whl\n",
      "Requirement already satisfied: filelock in ./jace/lib/python3.10/site-packages (from torch==2.5.0a0+872d972e41.nv24.08.17622132) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./jace/lib/python3.10/site-packages (from torch==2.5.0a0+872d972e41.nv24.08.17622132) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./jace/lib/python3.10/site-packages (from torch==2.5.0a0+872d972e41.nv24.08.17622132) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./jace/lib/python3.10/site-packages (from torch==2.5.0a0+872d972e41.nv24.08.17622132) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./jace/lib/python3.10/site-packages (from torch==2.5.0a0+872d972e41.nv24.08.17622132) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./jace/lib/python3.10/site-packages (from torch==2.5.0a0+872d972e41.nv24.08.17622132) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./jace/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.5.0a0+872d972e41.nv24.08.17622132) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./jace/lib/python3.10/site-packages (from jinja2->torch==2.5.0a0+872d972e41.nv24.08.17622132) (3.0.2)\n",
      "torch is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-2.5.0a0+872d972e41.nv24.08.17622132-cp310-cp310-linux_aarch64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.1 in ./jace/lib/python3.10/site-packages (1.26.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./jace/lib/python3.10/site-packages (4.48.0)\n",
      "Requirement already satisfied: Pillow in ./jace/lib/python3.10/site-packages (11.1.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in ./jace/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: opencv-python in ./jace/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: filelock in ./jace/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in ./jace/lib/python3.10/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./jace/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./jace/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./jace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./jace/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./jace/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./jace/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./jace/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./jace/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./jace/lib/python3.10/site-packages (from accelerate>=0.26.0) (6.1.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./jace/lib/python3.10/site-packages (from accelerate>=0.26.0) (2.5.0a0+872d972e41.nv24.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./jace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./jace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./jace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./jace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./jace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./jace/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./jace/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jace/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jace/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jace/lib/python3.10/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./jace/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers Pillow 'accelerate>=0.26.0' opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jemar/Downloads/jace-llava-onevision/jace/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set CUDA environment and device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Load model and processor\n",
    "model_id = \"llava-hf/llava-onevision-qwen2-0.5b-ov-hf\"\n",
    "model = LlavaOnevisionForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(0)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 893,675,552\n",
      "Trainable Parameters: 893,675,552\n"
     ]
    }
   ],
   "source": [
    "# Log model parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated (MB): 1723.32\n",
      "Max memory allocated (MB): 1723.32\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA memory usage after model loading\n",
    "print(f\"Memory allocated (MB): {torch.cuda.memory_allocated(0) / (1024 ** 2):.2f}\")\n",
    "print(f\"Max memory allocated (MB): {torch.cuda.max_memory_allocated(0) / (1024 ** 2):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening webcam to capture images...\n",
      "Press 's' to capture an image and 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "# Function to capture an image from the webcam\n",
    "def capture_image_from_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not access the webcam.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Press 's' to capture an image and 'q' to quit.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image from webcam.\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Webcam Feed\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('s'):  # Save the image on 's' key press\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        elif key == ord('q'):  # Quit on 'q' key press\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return None\n",
    "\n",
    "# Capture an image from the webcam\n",
    "print(\"Opening webcam to capture images...\")\n",
    "webcam_image = capture_image_from_webcam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image captured successfully.\n",
      "Processing the captured image...\n",
      "Memory allocated after inputs (MB): 1735.74\n",
      "Max memory allocated after inputs (MB): 2029.29\n",
      "Generating outputs...\n",
      "Memory allocated after inference (MB): 1735.74\n",
      "Max memory allocated after inference (MB): 2029.31\n",
      "Decoding output...\n",
      " \n",
      "What is this?assistant\n",
      "The image shows a person wearing a lanyard with a badge around their neck. The badge appears to have text on it, but the specific details are not clear due to the angle and resolution of the photo. The person is also wearing a white t-shirt with a graphic design on it. The setting seems to be an indoor environment, possibly an office or a public space, as there are other people and objects in the background.\n"
     ]
    }
   ],
   "source": [
    "if webcam_image is not None:\n",
    "    print(\"Image captured successfully.\")\n",
    "    # Define a chat history and use `apply_chat_template` to get correctly formatted prompt\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What is this?\"},\n",
    "                {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    # Prepare inputs\n",
    "    print(\"Processing the captured image...\")\n",
    "    inputs = processor(images=webcam_image, text=prompt, return_tensors=\"pt\").to(0, torch.float16)\n",
    "\n",
    "    # Check CUDA memory usage after inputs are prepared\n",
    "    print(f\"Memory allocated after inputs (MB): {torch.cuda.memory_allocated(0) / (1024 ** 2):.2f}\")\n",
    "    print(f\"Max memory allocated after inputs (MB): {torch.cuda.max_memory_allocated(0) / (1024 ** 2):.2f}\")\n",
    "\n",
    "    # Generate output\n",
    "    print(\"Generating outputs...\")\n",
    "    output = model.generate(**inputs, max_new_tokens=200, do_sample=False)\n",
    "\n",
    "    # Check CUDA memory usage after inference\n",
    "    print(f\"Memory allocated after inference (MB): {torch.cuda.memory_allocated(0) / (1024 ** 2):.2f}\")\n",
    "    print(f\"Max memory allocated after inference (MB): {torch.cuda.max_memory_allocated(0) / (1024 ** 2):.2f}\")\n",
    "\n",
    "    # Decode and print result\n",
    "    print(\"Decoding output...\")\n",
    "    print(processor.decode(output[0][2:], skip_special_tokens=True))\n",
    "else:\n",
    "    print(\"No image was captured. Exiting.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
